{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fb2bffdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Collecting langchain-core<1.0.0,>=0.3.66\n",
      "  Downloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n",
      "Collecting langsmith>=0.1.17\n",
      "  Downloading langsmith-0.4.4-py3-none-any.whl (367 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (4.14.0)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Collecting orjson<4.0.0,>=3.9.14\n",
      "  Downloading orjson-3.10.18-cp310-cp310-win_amd64.whl (134 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-win_amd64.whl (495 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (2025.6.15)\n",
      "Requirement already satisfied: anyio in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Installing collected packages: zstandard, requests-toolbelt, orjson, langsmith, jsonpatch, langchain-core, langchain-text-splitters, async-timeout, langchain\n",
      "  Attempting uninstall: async-timeout\n",
      "    Found existing installation: async-timeout 5.0.1\n",
      "    Uninstalling async-timeout-5.0.1:\n",
      "      Successfully uninstalled async-timeout-5.0.1\n",
      "Successfully installed async-timeout-4.0.3 jsonpatch-1.33 langchain-0.3.26 langchain-core-0.3.66 langchain-text-splitters-0.3.8 langsmith-0.4.4 orjson-3.10.18 requests-toolbelt-1.0.0 zstandard-0.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\crosve\\desktop\\python testing\\cuda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "265f3468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fdd26dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    return text\n",
    "\n",
    "def chunk_text(text, chunk_size):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=50)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def get_embedding_model():\n",
    "    embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")\n",
    "    return embed_model\n",
    "\n",
    "def get_embeddings(embed_model, text: str):\n",
    "    embeddings = embed_model.get_text_embedding(text)\n",
    "    return embeddings\n",
    "\n",
    "def dot_product(vec1, vec2):\n",
    "    return sum(a * b for a, b in zip(vec1, vec2))\n",
    "\n",
    "def magnitude(vec):\n",
    "    return math.sqrt(sum(v**2 for v in vec))\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_prod = dot_product(vec1, vec2)\n",
    "    mag_vec1 = magnitude(vec1)\n",
    "    mag_vec2 = magnitude(vec2)\n",
    "\n",
    "    if mag_vec1 == 0 or mag_vec2 == 0:\n",
    "        return 0  # Handle division by zero\n",
    "\n",
    "    return dot_prod / (mag_vec1 * mag_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d7154a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I'm a recent graduate from hunter college. I have a bachelors in computer science with a minor in math. I'm currently working with TipTop technologies as\", \"a software engineer. I'm currently working on a passion project as well called csphere to help people stay ontop of their bookmarks and have them\", \"actually revisit them rather then pilling them up. I gym, run, like to explore coffee chops around nyc. Kinda of a coffee adict so if you lvoe coffee we'll get along just fine.\", \"My inetrest align in development and ai as I've always been fascinated by ai when I was growing up. I'm open to any jobs within the tech sector and would love to\", \"have a quick chat to see if a potential role aligns with my career intrests. For now I'm just going with the flow, making myself 1 percent better day by day until I become the\", 'engineer that I know I can become. Some of my favorite shows include one piece, suits, and any drama show ou can imagine.']\n"
     ]
    }
   ],
   "source": [
    "text_file = read_text_file(\"crosve.txt\")\n",
    "chunks = chunk_text(text_file, chunk_size=220)\n",
    "print(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fe11c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from pinecone import Pinecone, PodSpec\n",
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "\n",
    "pc = Pinecone(api_key=\"\")\n",
    "\n",
    "\n",
    "llm = GoogleGenAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=\"\",  # uses GOOGLE_API_KEY env var by default\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6761576a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of chunks:  6\n",
      "[{'_id': 'rec1', 'chunk_text': \"I'm a recent graduate from hunter college. I have a bachelors in computer science with a minor in math. I'm currently working with TipTop technologies as\"}, {'_id': 'rec2', 'chunk_text': \"a software engineer. I'm currently working on a passion project as well called csphere to help people stay ontop of their bookmarks and have them\"}, {'_id': 'rec3', 'chunk_text': \"actually revisit them rather then pilling them up. I gym, run, like to explore coffee chops around nyc. Kinda of a coffee adict so if you lvoe coffee we'll get along just fine.\"}, {'_id': 'rec4', 'chunk_text': \"My inetrest align in development and ai as I've always been fascinated by ai when I was growing up. I'm open to any jobs within the tech sector and would love to\"}, {'_id': 'rec5', 'chunk_text': \"have a quick chat to see if a potential role aligns with my career intrests. For now I'm just going with the flow, making myself 1 percent better day by day until I become the\"}, {'_id': 'rec6', 'chunk_text': 'engineer that I know I can become. Some of my favorite shows include one piece, suits, and any drama show ou can imagine.'}]\n"
     ]
    }
   ],
   "source": [
    "# embed_model = get_embedding_model()\n",
    "n = len(chunks)\n",
    "print(\"size of chunks: \", n)\n",
    "records = []\n",
    "for i in range(1, n + 1):\n",
    "    data = {\n",
    "        '_id' : f'rec{i}',\n",
    "        'chunk_text' : chunks[i - 1]\n",
    "\n",
    "    }\n",
    "    records.append(data)\n",
    "\n",
    "print(records)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d5b45d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = \"crosve-portfolio\"\n",
    "\n",
    "pinecone_index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e9a57ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone_index.upsert_records(\"portfolio\", records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c0894323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dimension': 1024,\n",
      " 'index_fullness': 0.0,\n",
      " 'metric': 'cosine',\n",
      " 'namespaces': {'example-namespace': {'vector_count': 4},\n",
      "                'portfolio': {'vector_count': 6}},\n",
      " 'total_vector_count': 10,\n",
      " 'vector_type': 'dense'}\n"
     ]
    }
   ],
   "source": [
    "# Wait for the upserted vectors to be indexed\n",
    "import time\n",
    "time.sleep(10)\n",
    "\n",
    "# View stats for the index\n",
    "stats = pinecone_index.describe_index_stats()\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a5079f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: rec3, score: 0.0009, text: actually revisit them rather then pilling them up. I gym, run, like to explore coffee chops around nyc. Kinda of a coffee adict so if you lvoe coffee we'll get along just fine. \n",
      "\n",
      "id: rec6, score: 0.0001, text: engineer that I know I can become. Some of my favorite shows include one piece, suits, and any drama show ou can imagine. \n",
      "\n",
      "id: rec2, score: 0.0, text: a software engineer. I'm currently working on a passion project as well called csphere to help people stay ontop of their bookmarks and have them \n",
      "\n",
      "id: rec5, score: 0.0, text: have a quick chat to see if a potential role aligns with my career intrests. For now I'm just going with the flow, making myself 1 percent better day by day until I become the \n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What does crosve like to do when he has free time?\"\n",
    "reranked_results = pinecone_index.search(\n",
    "    namespace=\"portfolio\",\n",
    "    query={\n",
    "        \"top_k\": 10,\n",
    "        \"inputs\": {\n",
    "            'text': query\n",
    "        }\n",
    "    },\n",
    "    rerank={\n",
    "        \"model\": \"bge-reranker-v2-m3\",\n",
    "        \"top_n\": 10,\n",
    "        \"rank_fields\": [\"chunk_text\"]\n",
    "    }   \n",
    ")\n",
    "\n",
    "content = []\n",
    "\n",
    "for hit in reranked_results['result']['hits'][:4]:\n",
    "  \n",
    "    content.append(hit['fields']['chunk_text'])\n",
    "\n",
    "    print(f\"id: {hit['_id']}, score: {round(hit['_score'], 4)}, text: {hit['fields']['chunk_text']} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "930b4414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a smart agent. A question would be asked to you and relevant information would be provided.    Your task is to answer the question and use the information provided. Question - What does crosve like to do when he has free time?. Relevant Information about crosve lucero - [\"actually revisit them rather then pilling them up. I gym, run, like to explore coffee chops around nyc. Kinda of a coffee adict so if you lvoe coffee we'll get along just fine.\", 'engineer that I know I can become. Some of my favorite shows include one piece, suits, and any drama show ou can imagine.', \"a software engineer. I'm currently working on a passion project as well called csphere to help people stay ontop of their bookmarks and have them\", \"have a quick chat to see if a potential role aligns with my career intrests. For now I'm just going with the flow, making myself 1 percent better day by day until I become the\"]. You may also use     any addional information you may find on the web to help you answer the question as well. Also answer the questions(s) like it were any regular conversation and sounds enthustiastic as well         Don't start off by saying 'based on the info provided' or anything like that.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"You are a smart agent. A question would be asked to you and relevant information would be provided.\\\n",
    "    Your task is to answer the question and use the information provided. Question - {query}. Relevant Information about crosve lucero - {[c for c in content]}. You may also use \\\n",
    "    any addional information you may find on the web to help you answer the question as well. Also answer the questions(s) like it were any regular conversation and sounds enthustiastic as well \\\n",
    "        Don't start off by saying 'based on the info provided' or anything like that.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bdcd9995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, Crosve sounds like a cool person! When he's got some free time, it looks like he enjoys hitting the gym, going for runs, and exploring coffee shops around NYC â€“ he's a self-proclaimed coffee addict! He's also working on a passion project called csphere and enjoys watching shows like One Piece and Suits.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.google_genai import GoogleGenAI\n",
    "\n",
    "\n",
    "llm = GoogleGenAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    api_key=\"AIzaSyCFkoBKhOg22JYeaCu4X9E91y6skg1GuYc\", \n",
    ")\n",
    "\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-cuda",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
